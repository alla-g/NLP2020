{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание № 1. Определение тональности отзывов\n",
    "### Елизавета Клыкова, БКЛ181\n",
    "## Пункт 1: сбор данных\n",
    "Для сбора материалов был выбран сайт https://bookmix.ru/ с отзывами на книги. С помощью краулера получим положительные и отрицательные отзывы на различные произведения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic\n",
    "%pycodestyle_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import nltk\n",
    "import re\n",
    "import requests\n",
    "import string\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import OrderedDict\n",
    "from nltk import *\n",
    "from nltk.corpus import stopwords\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from string import punctuation\n",
    "from tqdm.auto import tqdm\n",
    "morph = MorphAnalyzer()\n",
    "session = requests.session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала получим с основной страницы список ссылок на различные страницы с отзывами, затем соберем с этих страниц отзывы с рейтингом 1-2 или 5 звезд. (Для отрицательных возьмем оценки 1 или 2 звезды, т.к. отзывов с 1 звездой слишком мало.)\n",
    "\n",
    "*Простите за длинную строку, у меня все падает, когда пытаюсь ее переносить каким-либо способом :(*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5:80: E501 line too long (107 > 79 characters)\n"
     ]
    }
   ],
   "source": [
    "def get_links():\n",
    "    begin_with = 0  # индекс страницы в ссылке\n",
    "    links = []\n",
    "    for i in tqdm(range(20)):\n",
    "        url = f'https://bookmix.ru/comments/index.phtml?begin={begin_with}&num_point=20&num_points=20.html'\n",
    "        page = session.get(url).text\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        for block in soup.find_all('h5'):\n",
    "            link = block.find('a').attrs['href']\n",
    "            if link.startswith('/discussion'):\n",
    "                full_link = 'https://bookmix.ru' + link\n",
    "                links.append(full_link)\n",
    "        begin_with += 20\n",
    "    return links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, проходя по полученным ссылкам, будем собирать полные тексты отзывов, если рейтинг нам подходит (1-2 или 5 звезд)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews(links):\n",
    "    good_reviews = []\n",
    "    bad_reviews = []\n",
    "    for link in tqdm(links):\n",
    "        url = f'{link}.html'\n",
    "        page = session.get(url)\n",
    "        page.encoding = 'utf-8'\n",
    "        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "        reviews = soup.find_all('div', {'class': 'item-comment level1'})\n",
    "        for review in reviews:\n",
    "            rating = review.find('div', {'class': 'rating'})\n",
    "            if rating:  # иногда рейтинга нет\n",
    "                rating = str(rating.attrs['class'][-1][-1])\n",
    "            else:\n",
    "                pass\n",
    "            if rating == '1' or rating == '2' or rating == '5':\n",
    "                text = review.find(\n",
    "                    'div', {'class': 'comment-content'}).find('p').text\n",
    "                if rating == '5':\n",
    "                    good_reviews.append(text)\n",
    "                else:\n",
    "                    bad_reviews.append(text)\n",
    "    return good_reviews, bad_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36deefae44e7409b907dc8550233efce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c86e2729cf10483094e913402e924d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "good_reviews, bad_reviews = get_reviews(get_links())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, что получилось:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3747"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(good_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "301"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bad_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним полученные отзывы в два отдельных файла. В качестве разделителя будем использовать три звездочки, чтобы при необходимости можно было прочитать файл и корректно разделить отзывы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_reviews(filename, reviews):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        full_text = '***'.join(reviews)\n",
    "        f.write(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_reviews('good_reviews.txt', good_reviews)\n",
    "save_reviews('bad_reviews.txt', bad_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пункт 2: обработка данных\n",
    "Токенизируем слова, приведем к нижнему регистру и к начальной форме. Поскольку NLTK считает пунктуацию за слова, заменим знаки препинания (кроме дефиса) на пробелы и только потом применим word_tokenize.\n",
    "\n",
    "Посколько отрицательных отзывов всегда получается меньше, чем положительных, поступим так: возьмем для обучения количество плохих отзывов минус 5 (т.к. по 5 отзывов нам нужно для проверки). Можно взять фиксированное число, но первый способ надежнее, т.к. при новом запуске программы число плохих отзывов может как увеличиваться, так и уменьшаться.\n",
    "\n",
    "Я буду считывать отзывы из созданных ранее файлов (это удобнее, если не хочется запускать всю программу целиком)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('good_reviews.txt', encoding='utf-8') as f:\n",
    "    good_reviews = f.read().split('***')\n",
    "with open('bad_reviews.txt', encoding='utf-8') as f1:\n",
    "    bad_reviews = f1.read().split('***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnum = len(bad_reviews) - 5\n",
    "good_text = '\\n'.join(good_reviews[0:rnum])\n",
    "bad_text = '\\n'.join(bad_reviews[0:rnum])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    punct = list(re.sub('-', '', string.punctuation))\n",
    "    other_punct = ['``', \"\\'\\'\", '...', '--', 'https', '–',\n",
    "                   '—', '«', '»', '“', '”', '’', '***', '…']\n",
    "    rx = '[' + re.escape(''.join(punct + other_punct)) + ']'\n",
    "    word_list = word_tokenize((re.sub(rx, ' ', text)).lower())\n",
    "    lemmas = [morph.parse(w)[0].normal_form for w in word_list]\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_words = tokenize_text(good_text)\n",
    "bad_words = tokenize_text(bad_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пункт 3: составление тонального словаря\n",
    "\n",
    "Для каждого типа отзывов создадим частотный словарь и получим множество слов, частотность которых больше 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_freqlist(words):\n",
    "    freqlist = Counter()\n",
    "    for word in words:\n",
    "        if word.isalpha():\n",
    "            freqlist[word] += 1\n",
    "    freq_words = [k for k in list(freqlist.keys())\n",
    "                  if freqlist[k] > 2]\n",
    "    return set(freq_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_freqlist = make_freqlist(good_words)\n",
    "bad_freqlist = make_freqlist(bad_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, что получилось:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1224"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(good_freqlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1217"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bad_freqlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем пересечение полученных множеств и вычтем его из каждого из них."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = good_freqlist.intersection(bad_freqlist)\n",
    "good_freqlist.difference_update(common_words)\n",
    "bad_freqlist.difference_update(common_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, сколько слов осталось в каждом множестве:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "527"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(good_freqlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "520"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bad_freqlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пункт 4: определение тональности отзыва\n",
    "\n",
    "Токенизируем тестовые отзывы, а затем, перебирая слова в каждом отзыве, посчитаем, сколько слов положительной или отрицательной тональности встретилось в отзыве, будем определять, к какому типу относится этот отзыв. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_test_texts = [tokenize_text(t) for t in good_reviews[-5:]]\n",
    "bad_test_texts = [tokenize_text(t) for t in bad_reviews[-5:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_review_type(good_freqlist, bad_freqlist, review):\n",
    "    review_freqlist = Counter(review)\n",
    "    good_words = 0\n",
    "    bad_words = 0\n",
    "    for k in list(review_freqlist.keys()):\n",
    "        if k in good_freqlist:\n",
    "            good_words += int(review_freqlist[k])\n",
    "        elif k in bad_freqlist:\n",
    "            bad_words += int(review_freqlist[k])\n",
    "    if good_words > bad_words:\n",
    "        result = 'good'\n",
    "    elif bad_words > good_words:\n",
    "        result = 'bad'\n",
    "    else:\n",
    "        result = 'unknown'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь проверим работу программы на двух типах отзывов отдельно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for i, text in enumerate(good_test_texts):\n",
    "    results[str(i+1)+' good review'] = detect_review_type(\n",
    "        good_freqlist, bad_freqlist, text)\n",
    "for i, text in enumerate(bad_test_texts):\n",
    "    results[str(i+1)+' bad review'] = detect_review_type(\n",
    "        good_freqlist, bad_freqlist, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1 good review': 'good',\n",
       " '2 good review': 'good',\n",
       " '3 good review': 'good',\n",
       " '4 good review': 'good',\n",
       " '5 good review': 'good',\n",
       " '1 bad review': 'bad',\n",
       " '2 bad review': 'bad',\n",
       " '3 bad review': 'bad',\n",
       " '4 bad review': 'bad',\n",
       " '5 bad review': 'good'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, подсчитаем accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_detect_type(good_test_texts, bad_test_texts):\n",
    "    results = []  # тип отзывы по мнению программы\n",
    "    real_type = []  # верный тип отзыва\n",
    "    for text in good_test_texts:\n",
    "        predicted_type = detect_review_type(\n",
    "            good_freqlist, bad_freqlist, text)\n",
    "        results.append(predicted_type)\n",
    "        real_type.append('good')\n",
    "    for text in bad_test_texts:\n",
    "        predicted_type = detect_review_type(\n",
    "            good_freqlist, bad_freqlist, text)\n",
    "        results.append(predicted_type)\n",
    "        real_type.append('bad')\n",
    "    return accuracy_score(results, real_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_detect_type(good_test_texts, bad_test_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пункт 5: улучшение программы\n",
    "\n",
    "1 способ. В данном случае при определении тональности мы считали, что все слова, встретившиеся в том или ином тональном словаре, имеют одинаковый вес. Для улучшения точности можно было бы установить разный вес для слов, которые встречаются в том или ином типе отзывов очень часто, и более редких слов. Таким образом, слова, которые встречаются в отзывах определенного типа очень часто, влияли бы на результат больше, чем слова, которые в этом типе отзывов встречаются редко.\n",
    "\n",
    "2 способ. Мы использовали для определения тональности слова, но это не очень точный способ, поскольку такие показательные лексемы, как \"нравиться\", \"впечатлять\", могли встретиться в обоих типах текстов, а значит, не попали в тональные словари. Этого можно было бы избежать, используя биграммы: тогда биграмма \"не нравиться\" точно встречалась бы в отрицательных отзывых и, скорее всего, не встречалась бы в положительных. Но для того чтобы реализовать этот способ, нужна бОльшая выборка.\n",
    "\n",
    "3 способ. Поскольку наша выборка довольно маленькая, неплохо было бы еще на этапе сбора данных добавить какую-нибудь проверку, что полученный отзыв действительно соответствует заявленному рейтингу. Бывает так, что человек ошибается и пишет плохой отзыв, а потом случайно ставит 5 звезд, и наоборот (это, кстати, может влиять и на accuracy, если при проверке попадется такой отзыв с несоответствующим рейтингом). Конечно, отчасти от такого \"шума\" спасает отсечение редких слов при создании множеств, но нет никакой гарантии, что в каком-нибудь отзыве некоторое слово не встретится три раза и не испортит общую картину, попав не в тот словарь. На маленьких объемах данных такую проверку можно выполнить и вручную, а вот на более крупных становится сложнее: нужно как-то сравнивать каждый отзыв с другими отзывами той же тональности. Зато чем больше данных, тем меньше влияют ошибочно попавшие не в то множество отзывы: можно просто установить более жесткий фильтр по частотности, и они отсеются."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
