{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-xOJuV3TYB6"
   },
   "source": [
    "### Елизавета Клыкова, БКЛ181\n",
    "# Домашнее задание № 3. Определение топика\n",
    "\n",
    "1. Определить широкий топик текста с помощью gensim. На семинаре мы познакомились с \"обычным\" встроенным дженсимом, но у него есть улучшенная версия - mallet, для запуска которой надо скачать zip file, распаковать его, дать обертке для маллета path к файлу и запустить. (1 балл - базовая версия, 2 балла - версия с маллетом).\n",
    "2. Создать функцию или серию функций для подбора оптимального числа групп (1 балл за нахождение оптимального числа, еще 1 балл - если это реализовано через функцию).\n",
    "3. Создать функцию, которая будет определять для каждого текста только один широкий топик, самый главный. Для этого нужно создать счетчик, и каждый раз, когда в тексте будет встречаться одно из слов, соответсвующих данной теме, добавляйте к счетчику его вес. (2 балла)\n",
    "4. Получив несколько групп (наборов текста с общим топиком), посчитать внутри каждой группы tf_idf для каждого текста. Для этого нужно взять все тексты с одной темой за корпус и посчитать для каждого из них tf_idf. (3 балла)\n",
    "5. Для каждого текста определить слова с 5-ю самыми высокими tf_idf и записать их в таблицу.\n",
    "6. Вывод - таблица excel, csv или pandas, содержащая текст, его широкий топик и 5 tf_idf слов. (1 балл)\n",
    "7. Логичность и красота кода. (1 балл)\n",
    "8. Бонус: описать работу coherence score на русском (просто словами).\n",
    "\n",
    "## Пункты 1-2: широкий топик и оптимальное число\n",
    "\n",
    "Перед началом работы импортируем все необходимые модули."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "HioZfpjGTYCC"
   },
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic\n",
    "%pycodestyle_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "o3SQbqFJTYCM",
    "outputId": "f1893b4c-5a1e-4dd4-fafb-64526090d139"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import os\n",
    "import math\n",
    "import operator\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "from collections import OrderedDict\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "Z9CSmD60TYCW",
    "outputId": "cead08d9-b63c-442d-9893-9c5db775108d"
   },
   "outputs": [],
   "source": [
    "# NLTK\n",
    "import nltk\n",
    "from nltk import corpus\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IG0vc5XcTYCc"
   },
   "source": [
    "Считаем файл с данными и преобразуем его в pandas dataframe.\n",
    "\n",
    "*Здесь опять все падает при переносе строки, извините.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "id": "lcjnvQr-TYCd",
    "outputId": "7651ac23-5b37-483e-b18f-436547f70043"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1:80: E501 line too long (82 > 79 characters)\n"
     ]
    }
   ],
   "source": [
    "link = 'https://raw.githubusercontent.com/selva86/datasets/master/newsgroups.json'\n",
    "df = pd.read_json(link)\n",
    "target_names = df.target_names.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CF6pgjROTYCk"
   },
   "source": [
    "C помощью регулярных выражений очистим тексты от ненужных токенов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "AjTD4tMqTYCl"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4:18: W605 invalid escape sequence '\\S'\n",
      "4:24: W605 invalid escape sequence '\\S'\n",
      "4:29: W605 invalid escape sequence '\\s'\n",
      "7:18: W605 invalid escape sequence '\\s'\n"
     ]
    }
   ],
   "source": [
    "data = df.content.values.tolist()\n",
    "\n",
    "# Remove Emails\n",
    "data = [re.sub('[\\S]*@[\\S]*[\\s]?', '', sent) for sent in data]\n",
    "\n",
    "# Remove new line characters\n",
    "data = [re.sub('[\\s]+', ' ', sent) for sent in data]\n",
    "\n",
    "# Remove distracting single quotes\n",
    "data = [re.sub(\"\\'\", \"\", sent) for sent in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMBqtMzbTYCs"
   },
   "source": [
    "Токенизируем тексты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "oQwaoFMOTYCt"
   },
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "990s9HtUTYC2"
   },
   "outputs": [],
   "source": [
    "data_words = list(sent_to_words(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJhHkaHBTYC_"
   },
   "source": [
    "Создадим модели для выделения би- и триграмм:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "RkRWQc8aTYDA"
   },
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100)\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)\n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TA4SBgQZTYDG"
   },
   "source": [
    "Избавимся от стоп-слов, создадим биграммы и лемматизируем тексты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "4rJ7QL7cTYDH"
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc))\n",
    "             if word not in stop_words] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "meOO-P5yTYDM"
   },
   "outputs": [],
   "source": [
    "data_words_nostops = remove_stopwords(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "CgeynxoATYDR"
   },
   "outputs": [],
   "source": [
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Y3oqKyxSTYDZ"
   },
   "outputs": [],
   "source": [
    "data_words_bigrams = make_bigrams(data_words_nostops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Vhvfnu-XTYDf"
   },
   "outputs": [],
   "source": [
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent))\n",
    "        texts_out.append([token.lemma_ for token in doc\n",
    "                          if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "b9KM0Qf5TYDm"
   },
   "outputs": [],
   "source": [
    "# Оставляем только часть, отвечающую за pos-tagging\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "K69uhVTGTYDu"
   },
   "outputs": [],
   "source": [
    "# Лемматизируем, оставляя только сущ., прил., глаголы и наречия\n",
    "data_lemmatized = lemmatization(\n",
    "    data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Записываем лемматизированные тексты в dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "jEUVNythTYDy"
   },
   "outputs": [],
   "source": [
    "df['lem_text'] = data_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "cLH_btBOTYD4"
   },
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7pCwvECrTYEA"
   },
   "source": [
    "Пытаемся запустить mallet, все падает, тратим 3 часа на решение проблемы, переходим в Colab, там та же проблема, пишем преподавателям, они разрешают не использовать mallet и обещают не снимать за это балл.................."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "EEayjkBITYEB",
    "outputId": "c2e5ea9a-e74b-4a27-b785-0463519aeccb"
   },
   "outputs": [
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'C:\\\\mallet-2.0.8\\\\bin\\\\mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input C:\\Users\\7045~1\\AppData\\Local\\Temp\\bcc68b_corpus.txt --output C:\\Users\\7045~1\\AppData\\Local\\Temp\\bcc68b_corpus.mallet' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-de28c904cbab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmallet_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr'C:\\\\mallet-2.0.8\\\\bin\\\\mallet'\u001b[0m  \u001b[1;31m# update this path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m ldamallet = gensim.models.wrappers.LdaMallet(\n\u001b[1;32m----> 3\u001b[1;33m     mallet_path, corpus=corpus, num_topics=20, id2word=id2word)\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\wrappers\\ldamallet.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, mallet_path, corpus, num_topics, alpha, id2word, workers, prefix, optimize_interval, iterations, topic_threshold, random_seed)\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_seed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfinferencer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\wrappers\\ldamallet.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, corpus)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m         \"\"\"\n\u001b[1;32m--> 272\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m         \u001b[0mcmd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmallet_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' train-topics --input %s --num-topics %s  --alpha %s --optimize-interval %s '\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m             \u001b[1;34m'--num-threads %s --output-state %s --output-doc-topics %s --output-topic-keys %s '\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\wrappers\\ldamallet.py\u001b[0m in \u001b[0;36mconvert_input\u001b[1;34m(self, corpus, infer, serialize_corpus)\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0mcmd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcmd\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfcorpustxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfcorpusmallet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"converting temporary corpus to MALLET format with %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m         \u001b[0mcheck_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36mcheck_output\u001b[1;34m(stdout, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m   1916\u001b[0m             \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCalledProcessError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1917\u001b[0m             \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1919\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1920\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mCalledProcessError\u001b[0m: Command 'C:\\\\mallet-2.0.8\\\\bin\\\\mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input C:\\Users\\7045~1\\AppData\\Local\\Temp\\bcc68b_corpus.txt --output C:\\Users\\7045~1\\AppData\\Local\\Temp\\bcc68b_corpus.mallet' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "mallet_path = r'C:\\\\mallet-2.0.8\\\\bin\\\\mallet'  # update this path\n",
    "ldamallet = gensim.models.wrappers.LdaMallet(\n",
    "    mallet_path, corpus=corpus, num_topics=20, id2word=id2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3vwtHL9TYEJ"
   },
   "source": [
    "В общем, я пыталась, но придется вернуться с обычному gensim'у.\n",
    "\n",
    "Чтобы два раза не вставать, начнем с подбора оптимального числа топиков, а затем на этом числе обучим финальный вариант модели. Я увеличиваю passes до 15 и прогоняю модель на кол-ве топиков от 7 до 28 с шагом 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "9ECv2T8rTYEs"
   },
   "outputs": [],
   "source": [
    "def find_opt_amount():\n",
    "    coherence_dict = {}\n",
    "    for i in tqdm(range(7, 31, 3)):\n",
    "        lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                                    id2word=id2word,\n",
    "                                                    num_topics=i,\n",
    "                                                    random_state=100,\n",
    "                                                    update_every=1,\n",
    "                                                    chunksize=100,\n",
    "                                                    passes=15,\n",
    "                                                    alpha='auto',\n",
    "                                                    per_word_topics=True)\n",
    "        doc_lda = lda_model[corpus]\n",
    "        coherence_model_lda = CoherenceModel(model=lda_model,\n",
    "                                             texts=data_lemmatized,\n",
    "                                             dictionary=id2word,\n",
    "                                             coherence='c_v')\n",
    "        coherence_lda = coherence_model_lda.get_coherence()\n",
    "        coherence_dict[i] = coherence_lda\n",
    "    opt_num = max(coherence_dict.items(), key=operator.itemgetter(1))[0]\n",
    "    return coherence_dict, opt_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "31f054a384bf462385529ca6c46ce232",
      "032f10b1e34948d8aa4d83cbb0e7e38c",
      "5a4c7a9d127148699ef7de28517ea96b",
      "3ebbca3b0efa47b2a1ab27a8611bd2d9",
      "a6fb5b58613f4e73b3e10cf6a857d279",
      "cfeeb1802e9e4bfb8131d4b76396aeb3",
      "c268d62a5e8d4054886b1fa5ac07095f",
      "ef28736c04ae48afa3268dc7f1f9d375"
     ]
    },
    "id": "YfdvlorvWwPy",
    "outputId": "1e68c60c-bc45-4a1f-ba97-beb75837c8ab"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc591e426114c589c88d29f0aa26013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coherences, opt_num = find_opt_amount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "id": "GW24ZTlr3Owi",
    "outputId": "5c9ddfeb-9dcc-4535-e05d-220dd5d45f1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5318282740836165"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherences[opt_num]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUUkZNAisY5H"
   },
   "source": [
    "Обучим модель на оптимальном числе топиков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "PWyWbF06sXRR"
   },
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                            id2word=id2word,\n",
    "                                            num_topics=opt_num,\n",
    "                                            random_state=100,\n",
    "                                            update_every=1,\n",
    "                                            chunksize=100,\n",
    "                                            passes=10,\n",
    "                                            alpha='auto',\n",
    "                                            per_word_topics=True)\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6jKF4hmC4dP_"
   },
   "source": [
    "Посмотрим, что получилось:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "id": "ODIDkFBe4AYp",
    "outputId": "ccc95869-4960-4bf9-c527-10d2d3dd4373"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.031*\"file\" + 0.024*\"window\" + 0.020*\"program\" + 0.013*\"entry\" + 0.013*\"image\" + 0.013*\"patient\" + 0.011*\"problem\" + 0.011*\"disk\" + 0.010*\"screen\" + 0.010*\"run\"'),\n",
       " (1,\n",
       "  '0.015*\"people\" + 0.013*\"would\" + 0.012*\"say\" + 0.009*\"write\" + 0.009*\"may\" + 0.008*\"think\" + 0.008*\"make\" + 0.007*\"believe\" + 0.007*\"reason\" + 0.007*\"know\"'),\n",
       " (2,\n",
       "  '0.010*\"kill\" + 0.007*\"child\" + 0.007*\"people\" + 0.006*\"say\" + 0.006*\"report\" + 0.006*\"attack\" + 0.006*\"hockey\" + 0.006*\"israeli\" + 0.006*\"fire\" + 0.006*\"war\"'),\n",
       " (3,\n",
       "  '0.025*\"line\" + 0.020*\"write\" + 0.016*\"would\" + 0.014*\"be\" + 0.014*\"go\" + 0.013*\"get\" + 0.012*\"article\" + 0.010*\"good\" + 0.010*\"know\" + 0.010*\"nntp_poste\"'),\n",
       " (4,\n",
       "  '0.047*\"key\" + 0.017*\"public\" + 0.014*\"internet\" + 0.014*\"encryption\" + 0.013*\"church\" + 0.012*\"message\" + 0.011*\"security\" + 0.011*\"government\" + 0.010*\"chip\" + 0.009*\"ripem\"'),\n",
       " (5,\n",
       "  '0.692*\"ax\" + 0.007*\"tube\" + 0.004*\"voltage\" + 0.003*\"volt\" + 0.003*\"therapy\" + 0.003*\"rlk\" + 0.002*\"lq\" + 0.002*\"capacitor\" + 0.002*\"gehrel\" + 0.002*\"oo\"'),\n",
       " (6,\n",
       "  '0.015*\"use\" + 0.014*\"system\" + 0.013*\"line\" + 0.010*\"drive\" + 0.009*\"also\" + 0.009*\"need\" + 0.009*\"mail\" + 0.008*\"thank\" + 0.008*\"work\" + 0.007*\"card\"')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = lda_model.print_topics()\n",
    "topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пункт 3: один топик для каждого текста\n",
    "Преобразуем выдачу gensim'а в словарь для удобства дальнейшей работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_dict = OrderedDict()\n",
    "for topic in topics:\n",
    "    topic_dict[topic[0]] = topic[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic in topic_dict:\n",
    "    weight_dict = {}\n",
    "    word_list = topic_dict[topic].split(' + ')\n",
    "    for w in word_list:\n",
    "        weight = float(w.split('*')[0])\n",
    "        word = w.split('*')[1].strip('\"')\n",
    "        weight_dict[word] = weight\n",
    "    topic_dict[topic] = weight_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы получили словарь, в котором каждому топику соответствует вложенный словарь слов с их весами. Теперь зададим функцию, определяющую главный топик текста по словам, которые в нем встречаются. Для каждого слова будем проверять, входит ли оно в один из получившихся топиков, и если да, добавлять его вес к общему весу очередного топика в данном тексте. Главным топиком станет тот, вес которого будет больше всего."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_one_topic(text, topics):\n",
    "    topic_counter = {}\n",
    "    for topic in topics:\n",
    "        topic_weight = 0\n",
    "        for word in text:\n",
    "            if word in topics[topic]:\n",
    "                topic_weight += topics[topic][word]\n",
    "        topic_counter[topic] = topic_weight\n",
    "    main_topic = max(topic_counter.items(), key=operator.itemgetter(1))[0]\n",
    "    return main_topic, round(topic_counter[main_topic], 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим функцию на всех лемматизированных текстах, записывая топики и их веса в два списка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_topic_for_texts(data, topics):\n",
    "    main_topics = []\n",
    "    topic_weights = []\n",
    "    for text in data:\n",
    "        topic, weight = find_one_topic(text, topics)\n",
    "        main_topics.append(topic)\n",
    "        topic_weights.append(weight)\n",
    "    return main_topics, topic_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics, weights = one_topic_for_texts(data_lemmatized, topic_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишем топики и веса в датафрейм. Добавим также столбец index (понадобится для дальнейшей работы)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "      <th>lem_text</th>\n",
       "      <th>main_topic</th>\n",
       "      <th>topic_weight</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>[where, thing, car, nntp_poste, host, park, li...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.045</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>[si, poll, final, summary, final, call, si, cl...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.028</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>[question, engineering, computer, network, dis...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.125</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "      <td>[division, line, host, amber, write, write, ar...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.114</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "      <td>[question, organization, smithsonian_astrophys...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.050</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11309</td>\n",
       "      <td>From: jim.zisfein@factory.com (Jim Zisfein) \\n...</td>\n",
       "      <td>13</td>\n",
       "      <td>sci.med</td>\n",
       "      <td>[migraine, city, ny_bis, reply, line, cheap, a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.078</td>\n",
       "      <td>11310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11310</td>\n",
       "      <td>From: ebodin@pearl.tufts.edu\\nSubject: Screen ...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>[problem, screen, blank, sometimes, minor, phy...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031</td>\n",
       "      <td>11311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11311</td>\n",
       "      <td>From: westes@netcom.com (Will Estes)\\nSubject:...</td>\n",
       "      <td>3</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "      <td>[este, mount, case, organization, mail, group,...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.035</td>\n",
       "      <td>11312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11312</td>\n",
       "      <td>From: steve@hcrlgw (Steven Collins)\\nSubject: ...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "      <td>[line, nntp_poste, host, article, write, boy, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.107</td>\n",
       "      <td>11313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11313</td>\n",
       "      <td>From: gunning@cco.caltech.edu (Kevin J. Gunnin...</td>\n",
       "      <td>8</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "      <td>[gun, steal, organization, line, distribution_...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.035</td>\n",
       "      <td>11314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11314 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  target  \\\n",
       "0      From: lerxst@wam.umd.edu (where's my thing)\\nS...       7   \n",
       "1      From: guykuo@carson.u.washington.edu (Guy Kuo)...       4   \n",
       "2      From: twillis@ec.ecn.purdue.edu (Thomas E Will...       4   \n",
       "3      From: jgreen@amber (Joe Green)\\nSubject: Re: W...       1   \n",
       "4      From: jcm@head-cfa.harvard.edu (Jonathan McDow...      14   \n",
       "...                                                  ...     ...   \n",
       "11309  From: jim.zisfein@factory.com (Jim Zisfein) \\n...      13   \n",
       "11310  From: ebodin@pearl.tufts.edu\\nSubject: Screen ...       4   \n",
       "11311  From: westes@netcom.com (Will Estes)\\nSubject:...       3   \n",
       "11312  From: steve@hcrlgw (Steven Collins)\\nSubject: ...       1   \n",
       "11313  From: gunning@cco.caltech.edu (Kevin J. Gunnin...       8   \n",
       "\n",
       "                   target_names  \\\n",
       "0                     rec.autos   \n",
       "1         comp.sys.mac.hardware   \n",
       "2         comp.sys.mac.hardware   \n",
       "3                 comp.graphics   \n",
       "4                     sci.space   \n",
       "...                         ...   \n",
       "11309                   sci.med   \n",
       "11310     comp.sys.mac.hardware   \n",
       "11311  comp.sys.ibm.pc.hardware   \n",
       "11312             comp.graphics   \n",
       "11313           rec.motorcycles   \n",
       "\n",
       "                                                lem_text  main_topic  \\\n",
       "0      [where, thing, car, nntp_poste, host, park, li...           3   \n",
       "1      [si, poll, final, summary, final, call, si, cl...           6   \n",
       "2      [question, engineering, computer, network, dis...           3   \n",
       "3      [division, line, host, amber, write, write, ar...           3   \n",
       "4      [question, organization, smithsonian_astrophys...           3   \n",
       "...                                                  ...         ...   \n",
       "11309  [migraine, city, ny_bis, reply, line, cheap, a...           0   \n",
       "11310  [problem, screen, blank, sometimes, minor, phy...           0   \n",
       "11311  [este, mount, case, organization, mail, group,...           3   \n",
       "11312  [line, nntp_poste, host, article, write, boy, ...           3   \n",
       "11313  [gun, steal, organization, line, distribution_...           3   \n",
       "\n",
       "       topic_weight  index  \n",
       "0             0.045      1  \n",
       "1             0.028      2  \n",
       "2             0.125      3  \n",
       "3             0.114      4  \n",
       "4             0.050      5  \n",
       "...             ...    ...  \n",
       "11309         0.078  11310  \n",
       "11310         0.031  11311  \n",
       "11311         0.035  11312  \n",
       "11312         0.107  11313  \n",
       "11313         0.035  11314  \n",
       "\n",
       "[11314 rows x 7 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['main_topic'] = topics\n",
    "df['topic_weight'] = weights\n",
    "df['index'] = range(1, len(df) + 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пункты 4-5: tf_idf текстов и 5 слов с наибольшим значением\n",
    "Сначала запишем топики и соответствующие им тексты в словарь topic_groups для удобства работы. Леммы соединим в тексты, используя в качестве разделителя пробел. Кроме того, сохраним также и полные тексты, чтобы в конце записать получившиеся данные в новый датафрейм без обращения к текущему."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_groups = {}\n",
    "for topic in set(topics):\n",
    "    token_texts = list(df['lem_text'].loc[df['main_topic'] == topic])\n",
    "    ftexts = list(df['content'].loc[df['main_topic'] == topic])\n",
    "    texts = [' '.join(t) for t in token_texts]\n",
    "    text_to_ftext = {}\n",
    "    for i, ftext in enumerate(ftexts):\n",
    "        text_to_ftext[ftext] = texts[i]\n",
    "    topic_groups[topic] = text_to_ftext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию, которая получает на вход словарь со всеми текстами, разделенными по теме, считает в каждой группе tf-idf и определяет для каждого текста 5 слов с самым высоким tf-idf. Функция возвращает список списков, в которых лежат полный текст, лемматизированный текст, основной топик и 5 слов с наиболее высоким tf-idf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_words(vector, feature_names, top_n):\n",
    "    sorted_nzs = np.argsort(vector.data)[:-(top_n+1):-1]\n",
    "    return feature_names[vector.indices[sorted_nzs]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b079d859d8d34b0a8430d76ff73afbcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_text_info = []  # здесь будет информация обо всех текстах\n",
    "\n",
    "for group in tqdm(topic_groups):\n",
    "    full_texts = list(topic_groups[group].keys())\n",
    "    texts = [topic_groups[group][f_text] for f_text in full_texts]\n",
    "\n",
    "    # Находим tf-idf для набора текстов с одним топиком:\n",
    "    texts_as_vectors = vectorizer.fit_transform(texts)\n",
    "    feature_names = np.array(vectorizer.get_feature_names())\n",
    "\n",
    "    # Для каждого текста находим 5 слов с самым высоким tf-idf:\n",
    "    for i, text in enumerate(texts):\n",
    "        text_info = []\n",
    "        article_vector = texts_as_vectors[i, :]\n",
    "        words = get_top_words(article_vector, feature_names, 5)\n",
    "        text_info.append(full_texts[i])\n",
    "        text_info.append(text)\n",
    "        text_info.append(group)\n",
    "        text_info.append(words)\n",
    "        all_text_info.append(text_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученные данные запишем в новый датафрейм и выведем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>lem_text</th>\n",
       "      <th>topic</th>\n",
       "      <th>spec_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>From: kerr@ux1.cso.uiuc.edu (Stan Kerr)\\nSubje...</td>\n",
       "      <td>sigma_design double article write look informa...</td>\n",
       "      <td>0</td>\n",
       "      <td>[board, sigma_design, licensing, have, double]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>From: ab@nova.cc.purdue.edu (Allen B)\\nSubject...</td>\n",
       "      <td>significance purdue_university line article wr...</td>\n",
       "      <td>0</td>\n",
       "      <td>[tiff, complexity, image, inability, application]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>From: abarden@tybse1.uucp (Ann Marie Barden)\\n...</td>\n",
       "      <td>file line question exact entry parameter termi...</td>\n",
       "      <td>0</td>\n",
       "      <td>[ncd, boot, terminal, control, access]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>From: csyphers@uafhp..uark.edu (Chris Syphers)...</td>\n",
       "      <td>size line nntp_poste host uafhp uark alavi wri...</td>\n",
       "      <td>0</td>\n",
       "      <td>[font, small, uafhp, funky, uark]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>From: ab245@cleveland.Freenet.Edu (Sam Latonia...</td>\n",
       "      <td>need phone number western_digital problem orga...</td>\n",
       "      <td>0</td>\n",
       "      <td>[western_digital, love, crash, phone, copy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11309</td>\n",
       "      <td>From: ph12hucg@sbusol.rz.uni-sb.de (Carsten Gr...</td>\n",
       "      <td>gramme list saarlande rechenzentrum line nntp_...</td>\n",
       "      <td>6</td>\n",
       "      <td>[drive, slave, master, single, lead]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11310</td>\n",
       "      <td>From: rcasteto@watsol.uwaterloo.ca (Ron Castel...</td>\n",
       "      <td>line send ticket order information follow team...</td>\n",
       "      <td>6</td>\n",
       "      <td>[opponent, tor, reply, analyst, discount]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11311</td>\n",
       "      <td>From: glang@slee01.srl.ford.com (Gordon Lang)\\...</td>\n",
       "      <td>help identify video company research laborator...</td>\n",
       "      <td>6</td>\n",
       "      <td>[template, signal, rgb, exist, video]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11312</td>\n",
       "      <td>From: CCMB &lt;CCMB@MUSICA.MCGILL.CA&gt;\\nSubject: W...</td>\n",
       "      <td>ccmb system use line nntp_poste host small pro...</td>\n",
       "      <td>6</td>\n",
       "      <td>[ccmb, utility, pro, game, system]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11313</td>\n",
       "      <td>From: adrian@ora.COM (Adrian Nye)\\nSubject: im...</td>\n",
       "      <td>line reply thank many offer review book receiv...</td>\n",
       "      <td>6</td>\n",
       "      <td>[review, oreilly, associate, crash, lose]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11314 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               full_text  \\\n",
       "0      From: kerr@ux1.cso.uiuc.edu (Stan Kerr)\\nSubje...   \n",
       "1      From: ab@nova.cc.purdue.edu (Allen B)\\nSubject...   \n",
       "2      From: abarden@tybse1.uucp (Ann Marie Barden)\\n...   \n",
       "3      From: csyphers@uafhp..uark.edu (Chris Syphers)...   \n",
       "4      From: ab245@cleveland.Freenet.Edu (Sam Latonia...   \n",
       "...                                                  ...   \n",
       "11309  From: ph12hucg@sbusol.rz.uni-sb.de (Carsten Gr...   \n",
       "11310  From: rcasteto@watsol.uwaterloo.ca (Ron Castel...   \n",
       "11311  From: glang@slee01.srl.ford.com (Gordon Lang)\\...   \n",
       "11312  From: CCMB <CCMB@MUSICA.MCGILL.CA>\\nSubject: W...   \n",
       "11313  From: adrian@ora.COM (Adrian Nye)\\nSubject: im...   \n",
       "\n",
       "                                                lem_text  topic  \\\n",
       "0      sigma_design double article write look informa...      0   \n",
       "1      significance purdue_university line article wr...      0   \n",
       "2      file line question exact entry parameter termi...      0   \n",
       "3      size line nntp_poste host uafhp uark alavi wri...      0   \n",
       "4      need phone number western_digital problem orga...      0   \n",
       "...                                                  ...    ...   \n",
       "11309  gramme list saarlande rechenzentrum line nntp_...      6   \n",
       "11310  line send ticket order information follow team...      6   \n",
       "11311  help identify video company research laborator...      6   \n",
       "11312  ccmb system use line nntp_poste host small pro...      6   \n",
       "11313  line reply thank many offer review book receiv...      6   \n",
       "\n",
       "                                              spec_words  \n",
       "0         [board, sigma_design, licensing, have, double]  \n",
       "1      [tiff, complexity, image, inability, application]  \n",
       "2                 [ncd, boot, terminal, control, access]  \n",
       "3                      [font, small, uafhp, funky, uark]  \n",
       "4            [western_digital, love, crash, phone, copy]  \n",
       "...                                                  ...  \n",
       "11309               [drive, slave, master, single, lead]  \n",
       "11310          [opponent, tor, reply, analyst, discount]  \n",
       "11311              [template, signal, rgb, exist, video]  \n",
       "11312                 [ccmb, utility, pro, game, system]  \n",
       "11313          [review, oreilly, associate, crash, lose]  \n",
       "\n",
       "[11314 rows x 4 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = ['full_text', 'lem_text', 'topic', 'spec_words']\n",
    "new_df = pd.DataFrame(all_text_info, columns=column_names)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бонус: описание работы coherence score\n",
    "Topic coherence отражает уровень семантической близости слов, которые имеют наибольший вес внутри одного топика. Для каждого топика эта величина вычисляется как среднее либо медиана коэффициента близости всех пар N наиболее частотных слов. Если семантическая близость велика, то такой топик понятен человеку, а значит, его выделение обосновано. Если же она мала, то такой топик мог быть выделен просто потому, что при обучении модели ее попросили выделить больше топиков, чем нужно для того корпуса, который был дан на вход. Coherence score - среднее topic coherence всех топиков. Чем выше coherence score, тем качественнее модель."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw3_eaklykova.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "032f10b1e34948d8aa4d83cbb0e7e38c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31f054a384bf462385529ca6c46ce232": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5a4c7a9d127148699ef7de28517ea96b",
       "IPY_MODEL_3ebbca3b0efa47b2a1ab27a8611bd2d9"
      ],
      "layout": "IPY_MODEL_032f10b1e34948d8aa4d83cbb0e7e38c"
     }
    },
    "3ebbca3b0efa47b2a1ab27a8611bd2d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef28736c04ae48afa3268dc7f1f9d375",
      "placeholder": "​",
      "style": "IPY_MODEL_c268d62a5e8d4054886b1fa5ac07095f",
      "value": " 10/10 [40:47&lt;00:00, 244.76s/it]"
     }
    },
    "5a4c7a9d127148699ef7de28517ea96b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cfeeb1802e9e4bfb8131d4b76396aeb3",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a6fb5b58613f4e73b3e10cf6a857d279",
      "value": 10
     }
    },
    "a6fb5b58613f4e73b3e10cf6a857d279": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c268d62a5e8d4054886b1fa5ac07095f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cfeeb1802e9e4bfb8131d4b76396aeb3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef28736c04ae48afa3268dc7f1f9d375": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
